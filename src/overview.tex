\begin{todo}
  Discuss the overall framework, and highlight the major steps and challenges in learning and control.
\end{todo}

\begin{figure}[!t]
  \centering
  \includegraphics[width=\columnwidth]{overall}
  \caption{Overall.}
  \label{fig:overall}
\end{figure}

\iffalse

\subsection{Challenges in bridging machine learning and controls}
\label{SS:practical_challenges}

%The central idea is to obtain control-oriented models using machine learning or black-box modeling, and formulate the control problem in a way that receding horizon control (RHC) can still be applied and the optimization problem can be solved efficiently.

It is important to note that the standard machine learning regression used for prediction is fundamentally different from using machine learning for control synthesis. In the former, all the inputs to the model (also called regressors or features) are known, while in the latter some of the inputs that are the control variables must be optimized in real-time for desired performance. 
We next discuss the practical challenges in using machine learning algorithms for control.

\noindent \textbf{(1) Data quality:} Most of the historical data that are available from complex systems like buildings are based on some rule-based controllers. 
Therefore, the data may not be sufficient to explain the relationship between the inputs and the outputs. 
To obtain richer data with enough excitation in the inputs, new experiments must be done either by exciting the inputs randomly or by a procedure for optimal experiment design (OED) \cite{Emery1998,Fedorov2010}. 
This paper proposes a procedure for OED using Gaussian Processes (GP) to recommend control strategies.

\noindent \textbf{(2) Computational complexity:} Depending upon the learning algorithm, the output from a learned model is a non-linear, non-convex and sometimes non-differentiable (eg.~Random Forests \cite{Friedman2001}) function of the inputs with no closed-form expression. 
Using such models for control synthesis where some of the inputs must be optimized can lead to computationally intractable optimization. 
Our previous work uses an adaptation of Random Forests which overcomes this problem by separation of variables to derive a local linear input-output mapping at each time step \cite{JainCDC2017}.
This paper uses GPs for receding horizon control where the output mean and variance are analytical functions of the inputs, albeit non-convex.

\noindent \textbf{(3) Performance guarantees and robustness:} A desired characteristic for closed-loop control is to provide performance guarantees. 
This becomes hard when a black-box is used to replace a physical model. 
However, it is possible to provide probabilistic guarantees with a learning algorithm based on Gaussian Processes. 
GPs allow us to define chance constraints or account for model uncertainty in the cost while solving the optimization problem. This helps bound the performance errors with high confidence. 
Handling disturbance uncertainties or robustness to sensor failures in this framework is part of our on-going work and is thus excluded from this paper.

\noindent \textbf{(4) Model adaptability:} It is often the case that the model properties change with time, % (with seasons, for example),
and thus, the learned model must also be updated when required. 
The traditional mode of system identification, done repeatedly, can be time and cost prohibitive, especially in the case of buildings. 
In this paper, we show how GPs can be updated online to account for %seasonal
changes in the properties of the system.

%\noindent \textbf{(5) Interpretability of control decisions:} Besides the accuracy of synthesizing control strategies with machine learning in the loop, we are also interested in solutions that are interpretable and trustworthy. Thus, the DPC recommendations should have traceability so they can be verified to be stable and safe. This direction of research also forms part of our on-going work.

\subsection{Overcoming practical challenges}
To address these challenges, we can take two different approaches based on how machine learning is used to learn the models.

\noindent \textbf{(1) Mix of black-box and physics-based models:} In this approach, we use machine learning to learn only the dynamics of a sub-system or to model uncertainties in the dynamics. An example of former is in the use of machine learning for perception, and model-based control for low-level control in autonomous cars \cite{Urmson2008}. Examples on learning uncertainties in the models include \cite{Berkenkamp2015,Desaraju2016}.

\noindent \textbf{(2) Fully black-box models:} The full dynamical model can also be obtained using only machine learning algorithms. This deviates from the traditional notion of system identification where a physics-based structure is assumed to begin with. An example would be fully autonomous control using camera where control actions are mapped to raw image pixels \cite{Bojarski2016}. 
%The catch here is that, prior to learning, sufficiently large data could be generated by running the car in simulations.

For the application to building control in context of Demand Response, where there is a massive cost to physical modeling, this paper explores the latter route to bypass the modeling difficulties as summarized before. The data-driven approach allows to scale this methodology to multi-building campus and in general to many more applications like control of autonomous systems.

\subsection{Contributions}
\label{SS:contributions}
\begin{figure}[!t]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/overview.eps}
	\caption{Paper contributions: (1) Optimal experiment design sequentially samples the inputs and applies to the system to generate training data, (2) Model Predictive Controller uses a Gaussian Process model learned on the OED data for receding horizon control, (3) the new data generated by controller is used to update the model online.}
	\captionsetup{justification=centering}
    \vspace{-11pt}
	\label{F:intro}
\end{figure}
This paper addresses the aforementioned practical challenges using fully black-box models based on Gaussian Processes.
In particular, this paper has the following contributions.

\noindent \textbf{(1) Optimal experiment design:} We develop a procedure for optimal experiment design with the dynamical system in a closed-loop by exploiting the variance in the predictions from a GP model. We show that under limited system availability and operation constraints, OED can provide faster learning rate than uniform random sampling or pseudo binary random sampling, reducing the duration of functional tests by up to \(50\%\).
	
\noindent \textbf{(2) Stochastic Model Predictive Control:} We show that the dynamical GP model can be used for real-time closed-loop finite horizon receding horizon control with probabilistic guarantees on constraint satisfaction. We again use the variance in the predictions from a GP model to make decisions where the model is most confident. In the case of Demand Response, we show that GP controller provides the necessary curtaiment with maximum \(1.7\% \) prediction error.
	
\noindent \textbf{(3) Online model update:} We propose an online method to update the GP model as new data are generated by running the GP-based controller in a closed-loop with the physical system.
Our method maximizes the information gain to select the best subset of data to update the model, thereby reducing the need for repetitive functional tests as systems properties change with time.

An overview of the organization is shown in Fig.~\ref{F:intro}.
We apply all three methods to large-scale buildings in EnergyPlus \cite{Deru2011}, a high fidelity building simulation software.
In the context of load curtailment for Demand Response, we apply OED to recommend control strategies to learn a model, fast and accurately. We show that MPC with GPs can provide the desired load curtailment with high confidence. After running the controller for a few weeks, we update the GP model with newly collected data, thus avoiding the need for a functional test in a new season.

\fi

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
